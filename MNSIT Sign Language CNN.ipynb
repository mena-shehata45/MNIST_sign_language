{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJ0nfhWiYugLPB4X7DfHzm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nm7sftiIMkve"},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import csv\n","from torch.utils.data import DataLoader, TensorDataset\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"datamunge/sign-language-mnist\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9s3AWObMo2S","executionInfo":{"status":"ok","timestamp":1735841389801,"user_tz":-60,"elapsed":4908,"user":{"displayName":"Mena Shehata","userId":"06312203004133773634"}},"outputId":"82839838-bbe2-4283-9583-917509285352"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/datamunge/sign-language-mnist?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 62.6M/62.6M [00:00<00:00, 125MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/datamunge/sign-language-mnist/versions/1\n"]}]},{"cell_type":"code","source":["# Construct file paths\n","path_sign_mnist_train = f\"{path}/sign_mnist_train.csv\"\n","path_sign_mnist_test = f\"{path}/sign_mnist_test.csv\"\n","\n","def get_data(filename):\n","    with open(filename, 'r') as training_file:\n","        csv_reader = csv.reader(training_file, delimiter=',')\n","        first_line = True\n","        temp_images = []\n","        temp_labels = []\n","        for row in csv_reader:\n","            if first_line:\n","                # Skip header line\n","                first_line = False\n","            else:\n","                # Append label (first value)\n","                temp_labels.append(int(row[0]))\n","                # Append image data as a 28x28 array\n","                image_data = np.array(row[1:785], dtype=float)\n","                image_data_as_array = image_data.reshape(28, 28)\n","                temp_images.append(image_data_as_array)\n","\n","        # Convert lists to numpy arrays\n","        images = np.array(temp_images)\n","        labels = np.array(temp_labels)\n","    return images, labels\n","\n","# Load data\n","training_images, training_labels = get_data(path_sign_mnist_train)\n","testing_images, testing_labels = get_data(path_sign_mnist_test)\n","\n","\n","# Print shapes\n","print(training_images.shape)\n","print(training_labels.shape)\n","print(testing_images.shape)\n","print(testing_labels.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TocFBImSMq6l","executionInfo":{"status":"ok","timestamp":1735841397578,"user_tz":-60,"elapsed":7780,"user":{"displayName":"Mena Shehata","userId":"06312203004133773634"}},"outputId":"38ee5df8-d1ed-4a9f-a775-d201f6df2502"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(27455, 28, 28)\n","(27455,)\n","(7172, 28, 28)\n","(7172,)\n"]}]},{"cell_type":"code","source":["# Load data\n","training_images, training_labels = get_data(path_sign_mnist_train)\n","testing_images, testing_labels = get_data(path_sign_mnist_test)\n","\n","# Convert to torch tensors\n","training_images = torch.tensor(training_images, dtype=torch.float32)\n","testing_images = torch.tensor(testing_images, dtype=torch.float32)\n","training_labels = torch.tensor(training_labels, dtype=torch.long)\n","testing_labels = torch.tensor(testing_labels, dtype=torch.long)\n","\n","# Normalize the images by dividing by 255 to scale them between 0 and 1\n","training_images /= 255.0\n","testing_images /= 255.0\n","\n","# Flatten the images to (batch_size, 28*28) if you're using fully connected layers\n","training_images = training_images.view(-1, 1, 28, 28)  # Batch Size, Channels (1), Height (28), Width (28)\n","testing_images = testing_images.view(-1, 1, 28, 28)    # Same for testing data\n","\n","# Create TensorDatasets\n","train_dataset = TensorDataset(training_images, training_labels)\n","test_dataset = TensorDataset(testing_images, testing_labels)\n","\n","# Create DataLoader for batching\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Print shapes of tensors\n","print(training_images.shape)\n","print(training_labels.shape)\n","print(testing_images.shape)\n","print(testing_labels.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-Qh_PsC2OLY","executionInfo":{"status":"ok","timestamp":1735841404263,"user_tz":-60,"elapsed":6688,"user":{"displayName":"Mena Shehata","userId":"06312203004133773634"}},"outputId":"75f1bdbe-97b3-4681-8eb7-ca22adc0b90a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([27455, 1, 28, 28])\n","torch.Size([27455])\n","torch.Size([7172, 1, 28, 28])\n","torch.Size([7172])\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","\n","        # Adjust the first layer for grayscale images (1 input channel)\n","        self.conv1 = nn.Conv2d(1, 6, 3)        # 1 input channel (grayscale), 6 filters, 5x5 kernel\n","        self.pool = nn.MaxPool2d(2, 2)         # Max pooling layer with 2x2 pool size\n","        self.conv2 = nn.Conv2d(6, 16, 3)       # 6 input channels, 16 filters, 5x5 kernel\n","        self.fc1 = nn.Linear(16*5*5, 120)      # Fully connected layer (output from conv2)\n","        self.fc2 = nn.Linear(120, 84)          # Another fully connected layer\n","        self.fc3 = nn.Linear(84, 26)           # Output layer (26 classes for the alphabet)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n"],"metadata":{"id":"0_9dTuOYMw7r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","model = ConvNet().to(device)\n","\n","criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n","optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","epochs = 2\n","\n","for epoch in range(epochs):\n","\n","    for i, (training_images, training_labels) in enumerate(train_loader):\n","      model.train()\n","      training_images = training_images.to(device)\n","      training_labels = training_labels.to(device)\n","\n","      output = model(training_images).to(device)\n","\n","      loss_val = criterion(output, training_labels)\n","      #l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n","      #loss_val += 0.01 * l2_norm\n","\n","      loss_val.backward()\n","\n","      optimizer.step()\n","\n","      optimizer.zero_grad()\n","\n","    if epoch % 10 == 0:\n","      print(f\"Epoch {epoch}, Loss: {loss_val.item()}\")\n","\n"],"metadata":{"id":"SWYtewAQMzLF","executionInfo":{"status":"ok","timestamp":1735841428252,"user_tz":-60,"elapsed":17414,"user":{"displayName":"Mena Shehata","userId":"06312203004133773634"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"478397ec-de20-4253-aaac-c361a80534f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.11952153593301773\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    n_class_correct = [0 for _ in range(26)]  # Assuming 26 classes (A-Z)\n","    n_class_samples = [0 for _ in range(26)]  # Assuming 26 classes (A-Z)\n","\n","    # Iterate over the test set using the DataLoader\n","    for i, (testing_images, testing_labels) in enumerate(test_loader):\n","\n","        testing_images = testing_images.to(device)\n","        testing_labels = testing_labels.to(device)\n","\n","        # Get model outputs\n","        outputs = model(testing_images)\n","\n","        # Get predicted labels by finding the max log-probability\n","        _, predicted = torch.max(outputs, 1)\n","\n","        n_samples += testing_labels.size(0)\n","        n_correct += (predicted == testing_labels).sum().item()\n","\n","        # Update class-level correct and sample counts\n","        for j in range(testing_labels.size(0)):\n","            label = testing_labels[j].item()  # Get the label as a Python integer\n","            pred = predicted[j].item()  # Get the predicted label as a Python integer\n","\n","            # Check if the label is valid (i.e., within the range of your classes)\n","            if 0 <= label < 26:  # Ensure label is within class range\n","                if label == pred:\n","                    n_class_correct[label] += 1\n","                n_class_samples[label] += 1\n","            else:\n","                print(f\"Warning: Invalid label {label} encountered!\")\n","\n","    # Calculate overall accuracy\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'Accuracy of the network: {acc:.2f} %')\n","\n","    # Calculate class-wise accuracy\n","    for i in range(26):\n","        if n_class_samples[i] > 0:\n","            class_acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n","            print(f'Accuracy of class {i}: {class_acc:.2f} %')\n"],"metadata":{"id":"tF-rOUrOM0gk","executionInfo":{"status":"ok","timestamp":1735841429079,"user_tz":-60,"elapsed":835,"user":{"displayName":"Mena Shehata","userId":"06312203004133773634"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5313f56e-fd90-4b07-dce1-0a4b49abc824"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network: 87.40 %\n","Accuracy of class 0: 95.17 %\n","Accuracy of class 1: 100.00 %\n","Accuracy of class 2: 99.03 %\n","Accuracy of class 3: 100.00 %\n","Accuracy of class 4: 94.58 %\n","Accuracy of class 5: 99.60 %\n","Accuracy of class 6: 93.68 %\n","Accuracy of class 7: 84.86 %\n","Accuracy of class 8: 92.71 %\n","Accuracy of class 10: 81.27 %\n","Accuracy of class 11: 100.00 %\n","Accuracy of class 12: 88.83 %\n","Accuracy of class 13: 46.74 %\n","Accuracy of class 14: 98.78 %\n","Accuracy of class 15: 93.95 %\n","Accuracy of class 16: 82.93 %\n","Accuracy of class 17: 72.22 %\n","Accuracy of class 18: 82.11 %\n","Accuracy of class 19: 48.79 %\n","Accuracy of class 20: 72.56 %\n","Accuracy of class 21: 85.26 %\n","Accuracy of class 22: 88.83 %\n","Accuracy of class 23: 92.13 %\n","Accuracy of class 24: 83.13 %\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"w2pnbiIVM196"},"execution_count":null,"outputs":[]}]}